{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1936f40a-f03e-4ec0-84e1-b68dd7e07182",
   "metadata": {},
   "source": [
    "# Boostrapers\n",
    "\n",
    "## Yolov5 Classification and Bouding Box detection\n",
    "\n",
    "### Classification success estimate >99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fb2c128-263d-4c55-8c17-a44a9f270229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): opencv-python in /opt/conda/lib/python3.8/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): numpy in /opt/conda/lib/python3.8/site-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): matplotlib in /opt/conda/lib/python3.8/site-packages\n",
      "Cleaning up...\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python numpy matplotlib\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "befbcfad-6c92-43b1-a7f8-c44f46a29a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "path_annotrain = \"./datasets_train/train_annotation/_annotation.csv\"\n",
    "\n",
    "train_annotation = pd.read_csv(path_annotrain, index_col=0)\n",
    "\n",
    "bbox_train_full = train_annotation.loc[\n",
    "    :, [\"im_name\", \"x_min\", \"y_min\", \"x_max\", \"y_max\", \"class\"]\n",
    "]\n",
    "\n",
    "bbox_train_full['isCar'] = (bbox_train_full['class'] == \"car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6d2d777-983c-4391-b4d8-56308c1864af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "bbox_train, bbox_eval = train_test_split(\n",
    "    bbox_train_full, test_size=0.1, random_state=1234\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "593e1cce-2a39-4e5f-a49a-b2b65d0b5a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               im_name        x_min       y_min        x_max        y_max  \\\n",
      "0        107347968.jpg    40.000000  244.000000  1144.000000   637.000000   \n",
      "1         91160576.jpg     4.000000    9.000000    98.000000    76.000000   \n",
      "2        273809408.jpg    16.000000    4.000000   288.000000   191.000000   \n",
      "3        579534848.jpg    14.000000   23.000000   255.000000   178.000000   \n",
      "4        950599680.jpg     4.000000   70.000000   321.000000   215.000000   \n",
      "...                ...          ...         ...          ...          ...   \n",
      "9690    9403488242.jpg   132.238000  371.477774  1871.606000  1200.390494   \n",
      "14225   2224571280.jpg   242.737881  131.401610   686.737005   508.379060   \n",
      "15669    146443543.jpg   457.746240   69.630292  2103.768560  1532.364560   \n",
      "16445  15666905933.jpg  1365.900768  875.976000  1537.965792  1005.971328   \n",
      "9872    8379986555.jpg     0.000000    0.000000   798.000000  1200.000000   \n",
      "\n",
      "              class  isCar  \n",
      "0               car   True  \n",
      "1               car   True  \n",
      "2               car   True  \n",
      "3               car   True  \n",
      "4               car   True  \n",
      "...             ...    ...  \n",
      "9690   Land vehicle  False  \n",
      "14225    Coffee cup  False  \n",
      "15669        Flower  False  \n",
      "16445         Mouth  False  \n",
      "9872   Land vehicle  False  \n",
      "\n",
      "[2641 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(bbox_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18b7a30c-19aa-4e3e-8faf-03152e4f8b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               im_name       x_min        y_min        x_max        y_max  \\\n",
      "463      367919104.jpg   12.000000    23.000000   245.000000   176.000000   \n",
      "1102      42991616.jpg   24.000000    87.000000   365.000000   255.000000   \n",
      "21510  17379700870.jpg  413.602500   189.986310  1097.998500   796.654170   \n",
      "62      1007747072.jpg   43.000000    48.000000   611.000000   306.000000   \n",
      "774        4521984.jpg   24.000000   141.000000   721.000000   396.000000   \n",
      "...                ...         ...          ...          ...          ...   \n",
      "279      951386112.jpg   18.000000   128.000000   607.000000   398.000000   \n",
      "16590  14249824423.jpg  153.435744  1183.058784   268.728416  1265.862816   \n",
      "664      863567872.jpg    1.000000    15.000000   640.000000   319.000000   \n",
      "3039   16161138999.jpg  650.160000   107.572426   858.833000   611.557626   \n",
      "723      742522880.jpg   80.000000    82.000000   831.000000   572.000000   \n",
      "\n",
      "        class  isCar  \n",
      "463       car   True  \n",
      "1102      car   True  \n",
      "21510  Shorts  False  \n",
      "62        car   True  \n",
      "774       car   True  \n",
      "...       ...    ...  \n",
      "279       car   True  \n",
      "16590   Mouth  False  \n",
      "664       car   True  \n",
      "3039      Leg  False  \n",
      "723       car   True  \n",
      "\n",
      "[2376 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(bbox_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec2808f3-e1f5-4592-937d-b47cc742a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python numpy matplotlib\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "CONFIDENCE = 0.3 \n",
    "\n",
    "\n",
    "# loading the YOLO neural network\n",
    "config_path = \"yolov3.cfg\"\n",
    "weights_path = \"yolov3.weights\"\n",
    "labels = open(\"coco.names\").read().strip().split(\"\\n\") \n",
    "net = cv2.dnn.readNetFromDarknet(config_path, weights_path) \n",
    "\n",
    "\n",
    "def second_step(im_name): \n",
    "\n",
    "    path_name = 'datasets_train/train/'+ im_name \n",
    "    image = cv2.imread(path_name)\n",
    "    file_name = os.path.basename(path_name) \n",
    "    filename, ext = file_name.split(\".\") \n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    # create 4D blob\n",
    "    blob = cv2.dnn.blobFromImage(image, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    \n",
    "    # get the output predictions\n",
    "    ln = net.getLayerNames()\n",
    "    ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    layer_outputs=net.forward(ln)\n",
    "    \n",
    "    \n",
    "    #iteration over the neural network \n",
    "    boxes, confidences, class_ids = [], [], []\n",
    "    for output in layer_outputs:\n",
    "        for detection in output: #loop over each of the object detections\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores) \n",
    "            confidence = scores[class_id] \n",
    "            \n",
    "            if (confidence > CONFIDENCE): \n",
    "                box = detection[:4] * np.array([w, h, w, h])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "            \n",
    "    if ((2 not in class_ids) and (5 not in class_ids) and (7 not in class_ids)):  #we consider both buses and trucks as cars\n",
    "        return [False, [0,0,0,0]] #no car in the output predictions\n",
    "    \n",
    "    else:\n",
    "        indices = []\n",
    "        legal_indices = [2,5,7]\n",
    "                \n",
    "        for i in range(len(boxes)):  \n",
    "            if (class_ids[i] in legal_indices):\n",
    "                indices.append(i)\n",
    "\n",
    "        max = boxes[indices[0]][2] + boxes[indices[0]][3] #selection of the largest rectangle\n",
    "        max_id = indices[0]\n",
    "\n",
    "        for i in indices:\n",
    "            if boxes[i][2] + boxes[i][3] > max:\n",
    "                max = boxes[i][2] + boxes[i][3]\n",
    "                max_id = i\n",
    "        \n",
    "        x_min, y_min, w, h = boxes[max_id]\n",
    "        x_min, y_min, x_max, y_max = x_min, y_min, x_min + w, y_min + h\n",
    "            \n",
    "        return [True, [x_min, y_min, x_max, y_max]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6144025-5ab5-4cda-ad11-efaa0dee6851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, [40, -10, 475, 185]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_step('1000800256.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3361f5ea-5d29-4370-962b-1c2048b2e0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\n",
      "Premature end of JPEG file\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_41832/4195952148.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbbox_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mim_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'im_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msecond_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'isCar'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0merrors\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_41832/3412617549.py\u001b[0m in \u001b[0;36msecond_step\u001b[0;34m(im_name)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mln\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLayerNames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mln\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetUnconnectedOutLayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m#print(len(layer_outputs))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# iterating over rows using iterrows() function\n",
    "#errors = 0\n",
    "\n",
    "#for i, j in bbox_train.iterrows():\n",
    "#    im_name = j['im_name']\n",
    "#    result = second_step(im_name)\n",
    "#    if(result[0] != j['isCar']):\n",
    "#        errors += 1\n",
    "    \n",
    "#print(errors / len(bbox_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f0ac307-e62d-4c60-b03f-805a510af06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              im_name x_min y_min x_max y_max    e  classType\n",
      "0        85854523.jpg    26   643  1834  1300  NaN        1.0\n",
      "1     16663988681.jpg     0     0     0     0  NaN        0.0\n",
      "2     19090334369.jpg     0     0     0     0  NaN        0.0\n",
      "3        71540198.jpg    67    72  1783   762  NaN        1.0\n",
      "4        85427036.jpg   122   169  1049   656  NaN        1.0\n",
      "...               ...   ...   ...   ...   ...  ...        ...\n",
      "1019     89862599.jpg    10    75   961   521  NaN        1.0\n",
      "1020   7055251597.jpg     0     0     0     0  NaN        0.0\n",
      "1021   3848520911.jpg     0     0     0     0  NaN        0.0\n",
      "1022     73537501.jpg    53    71   528   365  NaN        1.0\n",
      "1023     98186923.jpg   145   119   767   512  NaN        1.0\n",
      "\n",
      "[1024 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "directory = './car_data/predict'\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=[\"im_name\", \"x_min\", \"y_min\", \"x_max\", \"y_max\", \"e\"])\n",
    "\n",
    "i = 0\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    result = second_step('./car_data/predict/' + filename)\n",
    "    \n",
    "    #print(result[0], result[1][0], result[1][1], result[1][2], result[1][3])\n",
    "    \n",
    "    \n",
    "    df = df.append({\n",
    "     \"im_name\": filename,\n",
    "     \"classType\": result[0],\n",
    "     \"x_min\": result[1][0],\n",
    "     \"y_min\": result[1][1],\n",
    "     \"x_max\": result[1][2],\n",
    "     \"y_max\": result[1][3],\n",
    "      }, ignore_index=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e31bdb5-249f-405d-aa80-1298a279a50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ./car_data/predict && rm -rf .ipynb_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9386233-f2f2-41d7-9cbb-dcc42ee46d2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_80528/3410720067.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'intermediate_solution.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_csv('intermediate_solution.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add3d5f6-dff8-44df-b097-e3dc8dcd559d",
   "metadata": {},
   "source": [
    "## Resnet34 Car Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6518a1bf-9c81-4dde-89f9-7dd36f6cbcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastai==1.0.39\n",
    "\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4db0c05-624c-4211-b8aa-9e5dea171ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737cf8ca-e367-4ada-8808-8f1742137c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bfc768-8cb4-43c4-8922-e3fde136a550",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='./car_data/train'\n",
    "\n",
    "list = os.listdir(data_dir) \n",
    "number_files = len(list)\n",
    "print(number_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7835c3-08fe-4a15-92b3-3cd56f5c7ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataBunch.from_folder(path,  \n",
    "                                  valid_pct=0.2,\n",
    "                                  ds_tfms=get_transforms(do_flip=True,flip_vert=False, max_rotate=90),\n",
    "                                  size=224,bs=64, \n",
    "                                  num_workers=0).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad39d16-4561-4411-a170-e68894211cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, models.resnet34, metrics=accuracy, model_dir=\"/tmp/model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb480031-9dbf-4676-b0ac-712af62f6f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7b7b2b-f583-4c08-8835-a5c0626ffbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd56332-09d7-4e42-947a-96c20129a819",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa94b90-0d4e-4e62-9e3d-de97b1b49258",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38560af-02cd-4dba-93f7-1c05f38e745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57287c17-4b5e-47bf-b31e-8a2b62e4a2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a97bdf-8480-4840-8a51-be198a69523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c54000b-cd5c-4d16-9d87-df81c6d7fde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze() \n",
    "learn.fit_one_cycle(4, max_lr=slice(1e-6,1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5426db94-0ec2-40e3-b5cb-7ac89d79d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('stage-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a052626-95ff-4a4f-b8fc-81fa5bb401a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10993530-7878-4c18-a69a-f19a4716a1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = Image.open(\"../input/final-car-train/car_data/test/AM General Hummer SUV 2000/00076.jpg\")\n",
    "#x = pil2tensor(image, np.float32)\n",
    "#preds_num = learn.predict(Image(x))[2].numpy()\n",
    "\n",
    "#trn_tfms, val_tfms = tfms_from_model(arch,sz) # get transformations\n",
    "im = open_image(\"../input/final-car-train/car_data/test/Audi 100 Wagon 1994/00192.jpg\")\n",
    "#learn.precompute=False # We'll pass in a raw image, not activations\n",
    "#reds = learn.predict_array(im[None])\n",
    "#p.argmax(preds) # preds are log probabilities of classes\n",
    "\n",
    "pred_class, pred_idx, outputs =   learn.predict(im)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
